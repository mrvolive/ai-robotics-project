\documentclass[a4paper,pdftex,12pt]{article}
\usepackage[T1]{fontenc} 
\usepackage[utf8]{inputenc} 

\usepackage[hscale=0.75,vscale=0.75,vmarginratio={85:100},heightrounded]{geometry} 

\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amsmath, amssymb}
\usepackage{color, eurosym}
\usepackage{float}
\usepackage{xspace} 
\usepackage{times}
\usepackage{listings}
\usepackage{xcolor}

% Code listing style
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\setlength{\textheight}{220mm}
\setlength{\textwidth}{150mm}
\setlength{\topmargin}{1mm}
\setlength{\headheight}{0mm}
\setlength{\headsep}{0mm}
\setlength{\oddsidemargin}{5mm}
\setlength{\parindent}{32mm}
\setlength{\parskip}{0mm}
\linespread{1.1}

\sloppy

% Macros
\newcommand{\inv}[1]    {\frac{1}{#1}}
\newcommand{\half}      {\frac{1}{2}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\sect}[1] {\overline{#1}}
\newcommand{\eqn}[2] {\begin{equation} \label{#1} #2 \end{equation}}
\newcommand{\eqnn}[1] {\begin{equation*} #1 \end{equation*}}

\title{Technical Report: AI in Robotics}
\author{
	Florian HEGELE (ULMP) \\
	Olivier MARAVAL (ULMP) \\
	Jonathan SILVA
}
\date{\today}
\parindent 0pt
\parskip 1ex

\begin{document}

\maketitle

\begin{abstract}
	This project presents an autonomous robotic system capable of recognizing road signs and executing appropriate vehicle maneuvers using a JetBot platform equipped with an onboard camera.
	The system combines computer vision techniques for lane following and sign detection with a state-machine-based control architecture to demonstrate real-time decision making.
	While implemented as a physical robot demonstration using the JetBot, the underlying technology is designed for translation display applications in intelligent transportation systems.
\end{abstract}

\section{Introduction}

\subsection{Application Scenario}

Drivers traversing unfamiliar regions often encounter signs in languages they do not understand, potentially leading to safety hazards or traffic violations.
This project addresses this challenge by developing a comprehensive system designed to detect road signs in real-time using an onboard camera and classify them according to their type and meaning.
Upon classification, the system will find a matching roadsign for the driver selected country and display it.

The demonstration implementation uses a JetBot mobile robot to simulate a vehicle, showcasing how the system can integrate sign recognition with autonomous control. In a full-scale implementation, rather than controlling vehicle motion directly, the system would display translated sign information on a dashboard interface.

\subsection{Technical Problems}

Several technical challenges were addressed during the development of this system.
Foremost among these was the requirement for real-time image processing to ensure efficient detection of road signs and lane markers at frame rates sufficient for autonomous control.
Additionally, robust sign classification was necessary to distinguish between different road sign types under varying lighting and viewing conditions.
The system also required the implementation of a reliable state machine to manage different driving scenarios and a communication architecture capable of establishing low-latency data transfer between vision processing and control systems.

\subsection{System Overview}

\subsection{Scientific Contribution}

The primary technical contributions of this work include the integration of classical computer vision techniques with a state-machine control architecture to enable autonomous navigation.
This includes the implementation of a modular RobotController class that manages hardware abstraction, kinematics, and state transitions.
Furthermore, the project developed a robust communication protocol for remote video streaming and command reception.

\section{Related Work and Basics}
\subsection{Road Sign Recognition}
\subsection{Lane Detection and Line following}
\subsection{Robot Kinematics}
\subsection{State Machines in Robotic}

\section{Concept, Algorithms and Implementation}
\subsection{System Architecture}

\section{Exemples and Results}

\section{Conclusion}
Coming soon...

\begin{thebibliography}{9}
	\bibitem{rplidar}
	RPLidar Python Library, \texttt{https://github.com/SkoltechRobotics/rplidar}
\end{thebibliography}

\end{document}
